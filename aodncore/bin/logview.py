#!/usr/bin/env python

"""
Script to parse and view logs generated by pipelines.
"""

import argparse
from collections import OrderedDict
import re
import sys


# regular expressions to match log format and define fields extracted from log
LOG_FIELDS = OrderedDict([
    ('time', r"(?P<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3})\s+"),
    ('level', r"(?P<level>[A-Z]+)\s+"),
    ('task_name', r"tasks.(?P<task_name>\w+)"),
    ('task_id', r"\[(?P<task_id>[0-9a-f-]+)\]\s+"),
    ('message', r"(?P<message>.*)")
])
INPUT_REGEX = re.compile(''.join(LOG_FIELDS.values()))
OUTPUT_FORMAT = '{time:20} {level:>9} {message}\n'


def parse_args():
    """Parse the command line"""
    parser = argparse.ArgumentParser()
    parser.add_argument('logfile', help='pipeline task log file')
    parser.add_argument('-t', '--task_id', help='lines for task_id', metavar='ID')
    parser.add_argument('-e', '--errors', help='error lines only', action='store_true')
    parser.add_argument('-w', '--warnings', help='warning & error lines only', action='store_true')
    parser.add_argument('-p', '--pattern', help='lines matching regex pattern', metavar='REGEX')

    args = parser.parse_args()

    return args


def parse_log(logfile):
    """
    Parse the log returning a list of log data. Each list item is a dictionary of fieldname: value pairs.

    :param str logfile: Path to log file
    :return: list of log details from each line.

    """
    # read all log lines
    with open(logfile) as log:
        lines = log.readlines()

    # parse each line
    log_data = []
    for line in lines:
        line = line.strip()

        m = INPUT_REGEX.match(line)
        if m is not None:
            log_data.append(m.groupdict())

        # TODO: deal with unformatted lines

    return log_data


def print_output(log_data, fmt=OUTPUT_FORMAT):
    """
    Print the log data to stdout.

    :param list log_data: List of log data as returned by parse_log
    :param str fmt: format string to convert log fields into a line of output

    """
    output = []
    for data in log_data:
        output.append(fmt.format(**data))
        # TODO: wrap long lines

    try:
        sys.stdout.writelines(output)
        sys.stdout.flush()
    except IOError:
        # this can happen if output is piped to `head` or `less`
        pass


def view_log(args):

    all_data = parse_log(args.logfile)

    # TODO: filtering
    task_id = getattr(args, 'task_id', None)

    levels = None
    if args.errors:
        levels = ('ERROR', 'CRITICAL')
    if args.warnings:
        levels = ('WARNING', 'ERROR', 'CRITICAL')

    pattern = None
    if hasattr(args, 'pattern'):
        pattern = re.compile(args.pattern)

    out_data = []
    for data in all_data:
        if task_id and data['task_id'] != task_id:
            continue
        if levels and data['level'] not in levels:
            continue
        if pattern and not pattern.search(data['message']):
            continue

        out_data.append(data)

    # format & print output
    print_output(out_data)


if __name__ == '__main__':
    args = parse_args()

    view_log(args)

    exit(0)
