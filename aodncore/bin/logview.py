#!/usr/bin/env python

"""
Script to parse and view logs generated by pipelines.
"""

import argparse
from collections import OrderedDict
import re
import sys


# location of logs
LOGDIR_BASE = '/sw/chef/src/tmp/p2_logs'
LOG_WATCH = LOGDIR_BASE + '/watchservice/pipeline_watchservice-stderr.log'
LOGDIR_CELERY = LOGDIR_BASE + '/celery'
LOGDIR_PROCESS = LOGDIR_BASE + '/process'

# regular expressions to match log format and define fields extracted from log
LOG_FIELDS = OrderedDict([
    ('time', r"(?P<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3})\s+"),
    ('level', r"(?P<level>[A-Z]+)\s+"),
    ('task_name', r"tasks.(?P<task_name>\w+)"),
    ('task_id', r"\[(?P<task_id>[0-9a-f-]+)\]\s+"),
    ('message', r"(?P<message>.*)")
])
INPUT_REGEX = re.compile(''.join(LOG_FIELDS.values()))
DEFAULT_FORMAT = '{time:20} {level:>9} {message}\n'


class LogViewer(object):
    """
    Class to parse logs written by pipelines and output various filtered or summary views.
    """

    def __init__(self, logfile):
        self.logfile = logfile

    def show(self, task_id=None, errors=False, warnings=False, pattern=None, fmt=DEFAULT_FORMAT):
        """
        Print a filtered & re-formatted view of the log to stdout

        :param str task_id: only include log for given task uuid
        :param bool errors: only include error log lines
        :param bool warnings: only include warning & error lines
        :param str pattern: only include log messages matching pattern (regular expression)
        :param str fmt: output format (fmt.format() applied to dict of LOG_FIELDS extracted from log)
        """

        levels = None
        if errors:
            levels = ('ERROR', 'CRITICAL')
        if warnings:
            levels = ('WARNING', 'ERROR', 'CRITICAL')
        if pattern:
            pattern = re.compile(pattern)

        with open(self.logfile) as log:
            for line in log:
                line = line.strip()

                # parse a line of log data
                m = INPUT_REGEX.match(line)
                if m is None:
                    # TODO: deal with unformatted lines
                    continue
                data = m.groupdict()

                # filter -- should we include this line?
                if task_id and data['task_id'] != task_id:
                    continue
                if levels and data['level'] not in levels:
                    continue
                if pattern and not pattern.search(data['message']):
                    continue
                # TODO: filter by handler step?

                # format & print the line
                line_out = fmt.format(**data)
                try:
                    sys.stdout.write(line_out)
                    sys.stdout.flush()
                except IOError:
                    # this can happen if output is piped to `head` or `less`
                    pass


def find_log(input_file):
    """
    Given the name of an uploaded file, find the log file from the pipeline process that handled it.

    :param str input_file: Name of uploaded file
    :return: Full path to log file.
    """
    # TODO: implement find_log
    # Things to try:
    #   Read LOG_WATCH file and find the file name
    #   Read all process logs in LOGDIR_PROCESS and use pattern match
    return ''


def parse_args():
    """Parse the command line"""
    parser = argparse.ArgumentParser()
    parser.add_argument('logfile', help='pipeline task log file')
    parser.add_argument('-t', '--task_id', help='lines for task_id', metavar='ID')
    parser.add_argument('-e', '--errors', help='error lines only', action='store_true')
    parser.add_argument('-w', '--warnings', help='warning & error lines only', action='store_true')
    parser.add_argument('-p', '--pattern', help='lines matching regex pattern', metavar='REGEX')
    parser.add_argument('-f', '--file', help='name of processed file')

    args = parser.parse_args()

    print('Args: {}\n'.format(args))

    if args.file:
        args.logfile = find_log(args.file)

    return args


if __name__ == '__main__':
    args = parse_args()

    # TODO: filter by file name (parent or child)

    lv = LogViewer(args.logfile)
    lv.show(task_id=args.task_id, errors=args.errors, warnings=args.warnings, pattern=args.pattern)

    exit(0)
